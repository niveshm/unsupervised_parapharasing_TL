## Unsupervised Paraphrasing using Transfer Learning
This is an implementation of a transfer learning approach based on unsupervised paraphrasing for Indic languages, which uses a T5 transformer-based architecture.

### Usage
- `model.py` has pretrained model and tokenizer related code.
- `data` folder have all the code related data preprocessing.
- `main.py` has code related to training the model on task adaptation.
- `ssmain.py` has the code related to training self supervised model
- `generate_data.py` has the code related to generating pseudo labels.
- `eval.py` has the code related to generating evalutation metrics.

All the file are ran plainly with python without any arguments.
